# Cthulhu-finetuned-mistral7B

# Mistral LoRA Fine-Tuning for Cthulhu Mythos

このリポジトリは、Hugging Faceの[**Mistral-7B-Instruct-v0.2**](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)モデルに対して、LoRA (Low-Rank Adaptation) を用いたファインチューニングをGoogle Colab上のA100 GPU（80GB）環境で行うためのノートブックです。本プロジェクトは、クトゥルフ神話に関する深い知識を持ったモデルを作成することを目的としています。

## モデルの説明

- **ファインチューニングの背景**  
  本モデルは、クトゥルフ神話に関する日本語WikipediaからAPIを使って取得したデータを基にファインチューニングを行っています。詳細は `data_lora_formatted.json` を参照してください。

- **特徴**  
  一般的な大規模言語モデルでは回答できない、クトゥルフ神話に関する深い知識について、より正確な回答が可能になるよう調整されています。ただし、現状では未だにハルシネーション（事実に基づかない誤情報生成）が多く見受けられます。

- **今後の改善点**  
  - **temperature の調整**：生成時の `temperature` パラメータを低く設定することで、回答の安定性を向上させることが期待できます。  
  - **学習用データのトークン長の調整**：入力の長さを最適化することで、文脈をより正確に捉え、ハルシネーションの軽減が見込まれます。  
  ※ ただし、これらの調整は計算リソースとの兼ね合いになるため、環境に応じてご検討ください。

- **実行環境**  
  本モデルは、Google ColabのA100 GPU（80GB）環境を用いて学習および推論を実施しました。高い計算リソースを活用することで、大規模なモデルのファインチューニングが可能となっています。

- **利用方法**  
  Hugging Face Hubからモデルを読み込むか、添付されているipynbファイルの各セルを順番に実行することで、ファインチューニング済みモデルを利用できます。

## 概要

このノートブックでは、以下の処理を実施します。

- **データ前処理**  
  入力データ（JSON形式で `{"text": "...", "output": "..."}` の形式）を、LoRAファインチューニングに適した形式（`{"instruction": "...", "response": "..."}`）に変換します。

- **データセットの読み込みとトークナイズ**  
  Hugging Faceの `datasets` ライブラリを利用してデータセットを読み込み、モデルのトークナイザを使ってプロンプト形式（例：`<s>[INST] ... [/INST] ...</s>`）に変換します。

- **モデルのロードとLoRA適用**  
  8bit量子化によりGPUメモリを効率化した状態で、Mistral-7Bモデルを読み込み、PEFTライブラリを用いてLoRAのアダプタを挿入します。

- **ファインチューニング**  
  Hugging Faceの `Trainer` API を使ってモデルの微調整を実行します。

- **推論テストおよびモデルの保存**  
  ファインチューニング後のモデルを保存し、簡単な推論テストを実施します。

- **Hugging Face Hubへのアップロード**  
  学習済みモデルを指定のリポジトリにアップロードします。

## 特徴

- LoRAを用いたパラメータ効率の良いファインチューニング
- 8bit量子化によるGPUメモリの節約
- Google ColabのA100 GPU（80GB）を用いた高速学習と推論
- Hugging Face Hubへの自動アップロード
- 一般的なモデルでは回答できないクトゥルフ神話に関する深い知識を学習
- 現状はハルシネーションが見られるが、temperature や入力トークン長の調整で改善の余地あり

## 必要環境

- Python 3.7以上
- Google Colab（または同等のJupyter環境）

必要なPythonパッケージは以下です。ノートブック冒頭でインストールしています。

- `transformers`
- `datasets`
- `peft`
- `accelerate`
- `bitsandbytes`
- `huggingface_hub`

## セットアップと使い方

1. **リポジトリをクローンまたはダウンロード**

   ```bash
   git clone https://github.com/<あなたのユーザ名>/<リポジトリ名>.git
   cd <リポジトリ名>
